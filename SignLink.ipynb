{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1s3u1JMDqo9V6p7AR46hfdb69tAzPW0wH",
      "authorship_tag": "ABX9TyOd5PsLSyeOcqr6DskDy66n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mthanish/Sign-Link/blob/main/SignLink.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING AND MODEL TRAINING"
      ],
      "metadata": {
        "id": "1Q3BTuBu8EwU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Y6wSKlCQ-sVM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "# Set all your paths and parameters here\n",
        "\n",
        "# 1. Paths in Google Drive\n",
        "DRIVE_ZIP_PATH = '/content/drive/MyDrive/SignLink 2.0/archive (1).zip'\n",
        "MODEL_SAVE_DIR = '/content/drive/MyDrive/SignLink 2.0/MyModel'\n",
        "\n",
        "# 2. Local Colab Paths (Temporary & Fast)\n",
        "# We unzip the data here for fast I/O\n",
        "LOCAL_DATA_DIR = '/content/dataset'\n",
        "\n",
        "# 3. Model & Training Parameters\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Clean up old data and unzip to Colab's local disk\n",
        "print(f\"Preparing local directory: {LOCAL_DATA_DIR}\")\n",
        "# Remove old data if it exists, ensuring a fresh unzip\n",
        "if os.path.exists(LOCAL_DATA_DIR):\n",
        "    shutil.rmtree(LOCAL_DATA_DIR)\n",
        "os.makedirs(LOCAL_DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Create the model save directory in your Drive\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Unzipping dataset from Drive to {LOCAL_DATA_DIR}...\")\n",
        "# Unzip quietly from your Drive to the fast local Colab disk\n",
        "!unzip -q \"{DRIVE_ZIP_PATH}\" -d \"{LOCAL_DATA_DIR}\"\n",
        "\n",
        "print(\"Unzipping complete. Data is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcKXa0CYuL6k",
        "outputId": "9c4a6337-02c3-4020-f190-582f7cd63b33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Preparing local directory: /content/dataset\n",
            "Unzipping dataset from Drive to /content/dataset...\n",
            "Unzipping complete. Data is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Load and Preprocess Data ---\n",
        "DATA_DIR = \"/content/dataset/images\"\n",
        "\n",
        "print(f\"Loading data from: {DATA_DIR}\")\n",
        "\n",
        "# --- Load Training Data (80% of the images) ---\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "# --- Load Validation Data (20% of the images) ---\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "# Get class names and count\n",
        "class_names = train_dataset.class_names\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(f\"\\nFound {NUM_CLASSES} classes: {class_names}\")\n",
        "\n",
        "# --- Configure dataset for performance ---\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# CHANGED: We removed .cache() from both lines\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "# --- ADD THIS CODE TO THE END OF CELL 3 ---\n",
        "\n",
        "print(\"\\n--- DEBUGGING CHECK ---\")\n",
        "try:\n",
        "    train_batches = tf.data.experimental.cardinality(train_dataset)\n",
        "    val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "\n",
        "    print(f\"Number of batches in train_dataset: {train_batches.numpy()}\")\n",
        "    print(f\"Number of batches in validation_dataset: {val_batches.numpy()}\")\n",
        "\n",
        "    if val_batches.numpy() == 0:\n",
        "        print(\"\\nERROR: Your validation dataset is EMPTY!\")\n",
        "        print(\"This is the reason for the 'KeyError'.\")\n",
        "        print(\"This might be because your dataset is too small or all files were assigned to 'train'.\")\n",
        "    else:\n",
        "        print(\"\\nSUCCESS: Your validation dataset is correctly loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred while checking datasets: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SZgvkwruN9T",
        "outputId": "fb42d505-d57f-4b47-f964-ce9b33a57793"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from: /content/dataset/images\n",
            "Found 196621 files belonging to 110 classes.\n",
            "Using 157297 files for training.\n",
            "Found 196621 files belonging to 110 classes.\n",
            "Using 39324 files for validation.\n",
            "\n",
            "Found 110 classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'All_Gone', 'Alone', 'Baby', 'Beside', 'Book', 'Bowl', 'Bridge', 'Call', 'Camp', 'Cartridge', 'Flower', 'Fond', 'Glove', 'H', 'Hang', 'High', 'House', 'How_Many', 'I want Food', 'I_m Good', 'IorMe', 'J', 'Man', 'Marry', 'Meat', 'Medal', 'Mid_Day', 'Middle', 'Money', 'Moon', 'Mother', 'Opposite', 'Pain', 'Prisoner', 'Ring', 'Rose', 'See', 'Short', 'Stop', 'Superior', 'Theif', 'There is Gun', 'Thick', 'Thin', 'Tobacco', 'Up', 'V', 'Victory', 'Watch', 'Write', 'a', 'aboard', 'afraid', 'agree', 'assistance', 'b', 'bad', 'become', 'c', 'college', 'd', 'del', 'doctor', 'e', 'f', 'friend', 'from', 'g', 'i', 'k', 'l', 'm', 'n', 'not fine', 'nothing', 'o', 'ok fine', 'p', 'pray', 'q', 'r', 's', 'secondary', 'skin', 'small', 'space', 'specific', 'stand', 't', 'today', 'u', 'unknown', 'w', 'warn', 'which', 'work', 'x', 'y', 'you', 'z']\n",
            "\n",
            "--- DEBUGGING CHECK ---\n",
            "Number of batches in train_dataset: 4916\n",
            "Number of batches in validation_dataset: 1229\n",
            "\n",
            "SUCCESS: Your validation dataset is correctly loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, num_classes):\n",
        "    \"\"\"Creates and returns a new CNN model.\"\"\"\n",
        "    model = Sequential([\n",
        "        Rescaling(1./255, input_shape=input_shape),\n",
        "\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- Build the model ---\n",
        "print(\"\\nBuilding the CNN model...\")\n",
        "INPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "model = build_model(INPUT_SHAPE, NUM_CLASSES)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "Fo3rE56KuQL-",
        "outputId": "60f186e0-a44a-4d03-a31c-cc510ed39c49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building the CNN model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling_2 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m8,388,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)            │        \u001b[38;5;34m28,270\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,270</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,510,382\u001b[0m (32.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,510,382</span> (32.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,510,382\u001b[0m (32.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,510,382</span> (32.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Train the Model ---\n",
        "import os\n",
        "# Create a checkpoint to save the best model during training\n",
        "# This is your safety net against Colab crashes\n",
        "checkpoint_path = os.path.join(MODEL_SAVE_DIR, \"best_model.h5\")\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',  # Save the model with the best validation accuracy\n",
        "    mode='max',\n",
        "    save_best_only=True,     # Only save if it's better than the previous best\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[checkpoint_callback]  # Pass in the checkpoint callback\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")\n",
        "print(f\"The best model was saved to {checkpoint_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9CBpUzjuSeO",
        "outputId": "9fa9c931-35cb-480c-a57a-22f6a34afd54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training ---\n",
            "\u001b[1m4916/4916\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3692 - loss: 2.3498\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90070, saving model to /content/drive/MyDrive/SignLink 2.0/MyModel/best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4916/4916\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 40ms/step - accuracy: 0.3693 - loss: 2.3496 - val_accuracy: 0.9007 - val_loss: 0.3590\n",
            "\n",
            "--- Training Complete ---\n",
            "The best model was saved to /content/drive/MyDrive/SignLink 2.0/MyModel/best_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Train the Model (AND Plot) ---\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Checkpoint Setup ---\n",
        "checkpoint_path = os.path.join(MODEL_SAVE_DIR, \"best_model.h5\")\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- Define the Plotting Function ---\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plots the accuracy and loss from the training history.\"\"\"\n",
        "\n",
        "    # Use .get() to safely check for keys. This avoids the KeyError.\n",
        "    acc = history.history.get('accuracy', [])\n",
        "    val_acc = history.history.get('validation_accuracy', [])\n",
        "    loss = history.history.get('loss', [])\n",
        "    val_loss = history.history.get('validation_loss', [])\n",
        "\n",
        "    if not acc or not val_acc:\n",
        "        print(\"\\n--- PLOTTING ERROR ---\")\n",
        "        print(\"Could not find 'accuracy' or 'validation_accuracy' in history.\")\n",
        "        print(\"This means validation did not run. Check your 'validation_data' argument.\")\n",
        "        print(f\"Keys found: {history.history.keys()}\")\n",
        "        return\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# --- Start Training ---\n",
        "print(\"\\n--- Starting Model Training (for 1 Epoch) ---\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=EPOCHS,  # This should be 1 from Cell 1\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")\n",
        "\n",
        "# --- Plot Results Immediately ---\n",
        "print(\"\\n--- Plotting Results ---\")\n",
        "plot_training_history(history)\n",
        "\n",
        "# --- Save the Final Epoch Model ---\n",
        "final_model_path = os.path.join(MODEL_SAVE_DIR, 'final_epoch_model.h5')\n",
        "model.save(final_model_path)\n",
        "print(f\"Final epoch model saved to {final_model_path}\")"
      ],
      "metadata": {
        "id": "co4CNAGtuUis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d44f6ad-0085-459a-ec93-74685fc6930d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training (for 1 Epoch) ---\n",
            "\u001b[1m4916/4916\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7965 - loss: 0.6219\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95072, saving model to /content/drive/MyDrive/SignLink 2.0/MyModel/best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4916/4916\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 36ms/step - accuracy: 0.7965 - loss: 0.6219 - val_accuracy: 0.9507 - val_loss: 0.1698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Complete ---\n",
            "\n",
            "--- Plotting Results ---\n",
            "\n",
            "--- PLOTTING ERROR ---\n",
            "Could not find 'accuracy' or 'validation_accuracy' in history.\n",
            "This means validation did not run. Check your 'validation_data' argument.\n",
            "Keys found: dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n",
            "Final epoch model saved to /content/drive/MyDrive/SignLink 2.0/MyModel/final_epoch_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# --- This assumes your 'class_names' variable is still in memory ---\n",
        "# If it's not, just re-run Cell 3 to create it again\n",
        "\n",
        "if 'class_names' in locals():\n",
        "    # Get the MODEL_SAVE_DIR from Cell 1\n",
        "    labels_path = os.path.join(MODEL_SAVE_DIR, 'labels.json')\n",
        "\n",
        "    with open(labels_path, 'w') as f:\n",
        "        json.dump(class_names, f)\n",
        "\n",
        "    print(f\"Labels saved successfully to: {labels_path}\")\n",
        "    print(\"You can now download 'best_model.h5' and 'labels.json'\")\n",
        "else:\n",
        "    print(\"Error: 'class_names' not found. Please re-run Cell 3 to generate it.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fw3HQ3VlW-KD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7177b2a-b316-4a69-a9ea-57f1d6ff3422"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels saved successfully to: /content/drive/MyDrive/SignLink 2.0/MyModel/labels.json\n",
            "You can now download 'best_model.h5' and 'labels.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vErJqZD7qbmV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}